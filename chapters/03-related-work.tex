\chapter{Related work}

In this chapter I will present some of the work that has already been done in the field of containerization, and show what we can take from it.  I will then explain why my work adds up something to those previous research.

\section{Container and Virtual Machine performances}
As said previously, Virtual Machines have been kept away from the PaaS world, because of the greater overhead that Virtualization has on booting time and resources consumptions of the isolated system created.  This paper \cite{dua2014virtualization} made a detailed point about it back in 2014, emphasizing on three points that needed to be improved for the next generation of containers: Security, OS Independence and Standardization.  The last one meaning that containers runtime should establish some common requirements, come up with a common container format.  We have seen this appear since then, under the OCI (Open Container Initiative) specifications.  A thradeoff with the performances (mostly I/O) of the application running isolated is much more evident with virtualisation than with containerisation\cite{felter2015updated}.

\paragraph{}But recently things started to change, some new solutions seem to have the advantage of both sides, the isolation of a VM and the portability and lightness of a Container.  This is why some VM-based solution are presented here.  Even though VMs do not come from the same domain of application as Containers, and even though in the case of INGInious, Containers were 5 years ago the obvious choice, it might now be time to reconsider it.

\section{SAND} 
\paragraph{}SAND\cite{akkus2018sand} aims at improving the performance of serverless computing with two techniques: application-level sandboxing, and a hierarchical message bus:
\begin{itemize}
\renewcommand\labelitemi{--}
  \item \textbf{Application Sandboxing}: The key idea here is to differentiate multiple executions of different functions with multiple execution of a same function.  In the first case, as usual, a new container is launched on the new function demand and the function is executed inside of it.  In the second case, instead of lauching a new container with exactly the same configuration as an already running one, we only fork a process inside de running container to deal with the new demand, which is much faster than creating a new container.  The problem in our case, is that we loose the isolation between student code execution, which is not desirable.
  \item \textbf{Hierarchical Message Queuing}: The goal to this is to facilitate communication between functions that interact with one another (i.e. the output of a function is the input of another one).  To do so they use a two-level communication bus: global and local.  Global means that the communication is made between different functions on different hosts, while local means different functions on the same host.  As accessing the local bus is much faster than the global one, it can decrease latency for functions on the same host.  % In our case, as INGInious is still running on a single host, this shouldn't improve our performances that much.  But in a near future where INGInious get a new horizaontally scaled architecture, it might be interesting to come back on it.
\end{itemize}

\section{SOCK} \label{subsec-sock}
\paragraph{}"Sock (roughly for serverless-optimized containers), [is] a special-purpose container system with two goals: (1) \textit{low-latency invocation} for Python handlers that import librairies and (2) \textit{efficient sandbox initialization} so that individual workers can achive high ready-state throughput." \cite{oakes2018sock}  The final product created here isn't really something we could use for INGInious, it is a serverless solution (based on the Lambda model), targeting specifically python applications.  Though, in the process of creating this solution, they started from containers and deconstructed their perfromances, indentifying their bottlenecks.  And from this we can take those things:
\begin{itemize}
\renewcommand\labelitemi{--}
  \item Bind mounting is twice as fast as AUFS.  Even though AUFS (used by Docker) as a usefull Copy-on-write capability, we don't need to write to most of our files in our case, so using a read-only bind mounting for those files could allow us to avoid copying all file before startup, while still beeing able to edit the one with want to.
  \item Network namespaces creation and cleanup are costly, due to a single lock shared across all network namespaces.  We might gain some performances buy not adding network interfaces to containers that don't need it.
  \item Reusing a cgroup is at least twice as fast as creating a new one each time.  We could keep a pool of initialized cgroups, and only change the current container it controls.
\end{itemize}

\section{LightVM} 
\paragraph{}LigthVM is a complete redesign of Xen's toolstack which tried to bring some container's characteristics to VMs.  Such as fast instantiation (small startup time) and high instance density capability (high number of instances running in parallel on the same machine).\cite{manco2017my}  Xen is a Type-1\footnote{A Type-1 hypervisor is an hypervisor that runs on a bare-metal machine, whithout additional host.} hypervisor presented in 2003 with really low virtualization overheads and high hosting capacity, allowing a machine to host up to a 100 guest OS.\cite{barham2003xen}  
\paragraph{}They achieve such container's like performances by:
\begin{itemize}
\renewcommand\labelitemi{--}
  \item reducing the image size and the memory footprint of virtual machines.  They do so by including in the VM only what is necessary to the application that is meant to be executed in it.
  \item introducing noxs (no XenStore), a new implementation of Xen, without XenStore (which was a real bottleneck for fast instantiation of multiple VMs).
  \item splitting the Xen's toolstack into what can be run before the VM creation and what as to be done during it.  Allowing to pre-initialize VMs.
  \item replacing the Hotplug Script by xendevd, a binary deamon that can execute pre-defined setup more efficiently.
\end{itemize}

\paragraph{}They present four use cases with this solution, one of them beeing more intreresting for us: lightweight computation services, for which they rely on Minipython unikernel, to run computations written in Python, as a Faas could propose to do.  This would still be hard to use for INGInious, for the same reason as for SOCK (ยง\ref{subsec-sock}).

\section{Firecracker} 
\paragraph{} Firecracker is a new VMM (hypervisor) created specifically for serverless and containers applications.  \cite{agachefirecracker}  This is a solution provided by AWS, that very recently got deployed for two of their web services: Lambda (Faas) and Fargate (Paas).  We are basically getting here the good isolation of virtual machines and nearly as good performances and low overhead of containers.  Firecracker is based on KVM and provides minimal virtual machines (MicroVMs).  The configuration is done through a REST API.  Device emulation is available for disks, networking and serial console.  Network can be limited and so can disk throughput and request rate.  If proven to be easily usable in INGInious case, this would provide a better alternative to Docker regarding security.

\section{Summary}
\paragraph{}In this section, on Table \ref{tab:summary}, are quickly reminded the several solutions we explored in this chapter, along with some interesting infos about them.
\begin{table}[!h]

  \begin{center}
    \begin{tabular}{|p{.2\textwidth}|p{.1\textwidth}|p{.1\textwidth}|p{.1\textwidth}|p{.1\textwidth}|p{.1\textwidth}|p{.1\textwidth}|}
       \hline
       \textbf{Name} & \textbf{Pub.} & \textbf{Update} & \textbf{Open-Source} & \textbf{Pot. Sol.} & \textbf{Com.} & \textbf{Isol.} \\
       \hline
       SAND & 2018 & ? & ? & No & No & Cont. \\
       \hline
       SOCK & 2018 & ? & ? & No & No & Cont. or Runt. \\
       \hline
       LigthVM & 2017 & 2017 & Yes & No & No & Virt. \\
       \hline
       Firecracker & 2019 & 2020 & Yes & Yes & Yes & Virt.\\
       \hline
    \end{tabular}
  \end{center}
  \caption{Summary table of the different solutions explored in this chapter.}
  \label{tab:summary}
\end{table}
\paragraph{}\textbf{Caption}: 
\begin{itemize}
  \item \textit{Name}: The name of the project.
  \item \textit{Pub.}: The first publication year of the project.
  \item \textit{Update}: The last update year of the project.
  \item \textit{Open-source}: If the project is open-source.
  \item \textit{Pot. Sol.}: If the project could be a solution in our case.
  \item \textit{Com.}: If the project is a "commercial grade" solution.
  \item \textit{Isol.}: The type of isolation used in the project.
  \item \textit{Cont.}: Isolation by containerization.
  \item \textit{Virt.}: Isolation by virtualization.
  \item \textit{Runt.}: Isolation by the runtime of the application.
\end{itemize}

\section{My master thesis}
